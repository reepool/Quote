"""
Main entry point for the Quote System.
Provides command-line interface and system initialization.
"""

import asyncio
import argparse
import sys
from typing import Optional, List
from datetime import date, datetime


from utils import (
    scheduler_logger, dm_logger, tgbot_logger, api_logger, config_manager, get_process_manager
)
# ç›´æ¥å¯¼å…¥ä»£ç è½¬æ¢å·¥å…·ï¼Œé¿å…ä¾èµ–é—®é¢˜
from utils.code_utils import convert_to_database_format, is_valid_standard_format

from data_manager import data_manager
from scheduler.scheduler import task_scheduler
from scheduler.job_config import job_config_manager
from api.app import app as api_app
from utils.task_manager.task_manager import TaskManagerBot


class QuoteSystem:
    """è¡Œæƒ…ç³»ç»Ÿä¸»ç±»"""

    def __init__(self):
        self.config = config_manager
        self.running = False
        self.task_manager_bot = None
        self._telegram_bot = None
        self.process_manager = get_process_manager()
        self.service_name = "QuoteSystem"

    async def initialize(self, include_scheduler: bool = True):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            scheduler_logger.info("[Main] Initializing Quote System...")

            # æå‰åˆå§‹åŒ–TelegramBotï¼ˆç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½ä½¿ç”¨ï¼‰
            await self._initialize_telegram_bot()

            # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
            await data_manager.initialize()

            # åˆå§‹åŒ–è°ƒåº¦å™¨ç›‘æ§å™¨ (éœ€è¦ config_manager)
            from scheduler.monitor import SchedulerMonitor
            self.scheduler_monitor = SchedulerMonitor(self.config)

            if include_scheduler:
                # åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨
                await task_scheduler.initialize()

                # åˆå§‹åŒ–è°ƒåº¦å™¨ç›‘æ§
                await self.scheduler_monitor.initialize()

                # åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†æœºå™¨äºº
                await self._initialize_task_manager()

            scheduler_logger.info("[Main] Quote System initialized successfully")

        except Exception as e:
            scheduler_logger.error(f"[Main] Failed to initialize system: {e}")
            raise

    async def initialize_lightweight(self):
        """è½»é‡çº§åˆå§‹åŒ–ï¼Œåªåˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨ï¼ˆç”¨äºä¸éœ€è¦è°ƒåº¦å™¨çš„å‘½ä»¤ï¼‰"""
        try:
            scheduler_logger.info("[Main] Initializing Quote System (lightweight mode)...")

            # åªåˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨ï¼Œä¸åˆå§‹åŒ–è°ƒåº¦å™¨
            await data_manager.initialize()

            scheduler_logger.info("[Main] Quote System initialized successfully (lightweight mode)")

        except Exception as e:
            scheduler_logger.error(f"[Main] Failed to initialize system: {e}")
            raise

    async def start_scheduler_only(self):
        """ä»…å¯åŠ¨è°ƒåº¦å™¨"""
        try:
            scheduler_logger.info("[Main] Starting scheduler mode...")
            self.running = True

            # è®¾ç½®ä¿¡å·å¤„ç†
            self._setup_signal_handlers()

            # ä¿æŒè¿è¡Œ
            while self.running:
                await asyncio.sleep(1)

        except KeyboardInterrupt:
            scheduler_logger.info("[Main] Received keyboard interrupt, shutting down...")
        except Exception as e:
            scheduler_logger.error(f"[Main] Scheduler mode error: {e}")
        finally:
            await self.shutdown()

    async def start_api_server(self, host: str = None, port: int = None):
        """å¯åŠ¨APIæœåŠ¡å™¨"""
        try:
            # è·å–APIé…ç½®
            api_config = self.config.get_api_config()

            # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼ï¼Œå¦‚æœå‘½ä»¤è¡Œå‚æ•°æœªæä¾›
            final_host = host if host is not None else api_config.host
            final_port = port if port is not None else api_config.port

            api_logger.info(f"[Main] Starting API server on {final_host}:{final_port}...")
            api_logger.info(f"[Main] API config - workers: {api_config.workers}, reload: {api_config.reload}")

            import uvicorn
            config = uvicorn.Config(
                api_app,
                host=final_host,
                port=final_port,
                workers=api_config.workers,
                reload=api_config.reload,
                log_level="info"
            )
            server = uvicorn.Server(config)

            # å¯åŠ¨æœåŠ¡å™¨
            await server.serve()

        except Exception as e:
            api_logger.error(f"[Main] API server error: {e}")
            raise

    async def start_full_system(self, host: str = None, port: int = None):
        """å¯åŠ¨å®Œæ•´ç³»ç»Ÿï¼ˆè°ƒåº¦å™¨ + APIæœåŠ¡ï¼‰"""
        try:
            scheduler_logger.info("[Main] Starting full system mode (Scheduler + API Server)...")
            self.running = True

            # è®¾ç½®ä¿¡å·å¤„ç†
            self._setup_signal_handlers()

            # è·å–APIé…ç½®
            api_config = self.config.get_api_config()
            final_host = host if host is not None else api_config.host
            final_port = port if port is not None else api_config.port

            # å¯åŠ¨APIæœåŠ¡å™¨
            api_logger.info(f"[Main] Starting API server on {final_host}:{final_port}...")
            api_logger.info(f"[Main] API config - workers: {api_config.workers}, reload: {api_config.reload}")

            import uvicorn
            config = uvicorn.Config(
                api_app,
                host=final_host,
                port=final_port,
                workers=api_config.workers,
                reload=api_config.reload,
                log_level="info"
            )
            server = uvicorn.Server(config)

            # å¹¶å‘è¿è¡ŒAPIæœåŠ¡å™¨å’Œè°ƒåº¦å™¨
            api_task = asyncio.create_task(server.serve())
            scheduler_logger.info("[Main] API server started, scheduler is already running in background")

            # ç­‰å¾…ä¿¡å·æˆ–å¼‚å¸¸
            while self.running:
                await asyncio.sleep(1)

                # æ£€æŸ¥APIæœåŠ¡å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                if api_task.done():
                    try:
                        api_task.result()  # è¿™ä¼šæŠ›å‡ºå¼‚å¸¸å¦‚æœæœ‰é”™è¯¯
                    except Exception as e:
                        api_logger.error(f"[Main] API server crashed: {e}")
                        break

            # åœæ­¢APIæœåŠ¡å™¨
            if not api_task.done():
                api_logger.info("[Main] Shutting down API server...")
                server.should_exit = True
                try:
                    await asyncio.wait_for(api_task, timeout=10)
                except asyncio.TimeoutError:
                    api_logger.warning("[Main] API server shutdown timeout")
                    api_task.cancel()

        except KeyboardInterrupt:
            scheduler_logger.info("[Main] Received keyboard interrupt, shutting down full system...")
        except Exception as e:
            scheduler_logger.error(f"[Main] Full system mode error: {e}")
        finally:
            await self.shutdown()

    async def download_historical_data(self, exchanges: Optional[list] = None, years: Optional[list] = None,
                                      start_date: Optional[date] = None, end_date: Optional[date] = None,
                                      preset: Optional[str] = None, resume: bool = True):
        """ä¸‹è½½å†å²æ•°æ®"""
        try:
            dm_logger.info("[Main] Starting historical data download...")

            # å¤„ç†é¢„è®¾ç»„åˆ
            if preset:
                exchanges = self._get_preset_exchanges(preset)
                dm_logger.info(f"[Main] Using preset '{preset}': {exchanges}")
            elif exchanges is None:
                exchanges = ['SSE', 'SZSE', 'BSE']

            # åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ä»¥è·å–æœ€æ–°çš„ä¸Šå¸‚æ—¥æœŸä¿¡æ¯
            dm_logger.info("[Main] Using precise download mode (based on listed dates)")
            await self._refresh_instrument_list(exchanges)

            # å¤„ç†æ—¥æœŸèŒƒå›´å‚æ•°
            from datetime import date

            # å¦‚æœç›´æ¥æä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨å®ƒä»¬
            if start_date or end_date:
                if start_date and end_date:
                    dm_logger.info(f"[Main] Using specified date range: {start_date} to {end_date}")
                elif start_date:
                    dm_logger.info(f"[Main] Using start date: {start_date} to today")
                    end_date = date.today()
                elif end_date:
                    dm_logger.info(f"[Main] Using date range from beginning to {end_date}")
            # å¦åˆ™ä½¿ç”¨yearså‚æ•°
            elif years:
                # è®¡ç®—å¹´ä»½èŒƒå›´
                min_year = min(years)
                max_year = max(years)
                start_date = date(min_year, 1, 1)
                end_date = date(max_year, 12, 31)
                dm_logger.info(f"[Main] Using date range: {start_date} to {end_date} (from years: {years})")
            else:
                # è®©data_manageræ ¹æ®é…ç½®å†³å®šé»˜è®¤å¹´ä»½èŒƒå›´
                dm_logger.info(f"[Main] Using default date range (no date parameters provided)")

            # æ‰§è¡Œä¸‹è½½
            # åˆ¤æ–­æ˜¯å¦éœ€è¦å¼ºåˆ¶æ›´æ–°äº¤æ˜“æ—¥å†
            force_update_calendar = True  # é»˜è®¤å¼ºåˆ¶æ›´æ–°ï¼ˆå…¨å†å²ä¸‹è½½ï¼‰

            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸèŒƒå›´ï¼Œåˆ™ä¸ä½¿ç”¨ç»­ä¼ æ¨¡å¼ï¼ˆé‡æ–°ä¸‹è½½æŒ‡å®šèŒƒå›´ï¼‰
            if start_date or end_date:
                resume = False
                dm_logger.info("[Main] Specified date range, disabling resume mode")
                force_update_calendar = False
                dm_logger.info("[Main] Using cached trading calendar for partial date range download")
            elif resume and data_manager.progress.processed_instruments > 0:
                force_update_calendar = False
                dm_logger.info("[Main] Resume mode, using cached trading calendar")

            await data_manager.download_all_historical_data(
                exchanges, start_date, end_date, resume=resume,
                force_update_calendar=force_update_calendar
            )

            dm_logger.info("[Main] Historical data download completed")

        except Exception as e:
            dm_logger.error(f"[Main] Historical data download failed: {e}")
            raise

    async def _refresh_instrument_list(self, exchanges: List[str]):
        """åˆ·æ–°äº¤æ˜“å“ç§åˆ—è¡¨ï¼ˆè·å–æœ€æ–°çš„ä¸Šå¸‚æ—¥æœŸä¿¡æ¯ï¼‰"""
        try:
            dm_logger.info(f"[Main] Refreshing instrument list for exchanges: {exchanges}")

            from data_sources.source_factory import data_source_factory

            for exchange in exchanges:
                dm_logger.info(f"[Main] Refreshing instruments for {exchange}")

                # è·å–æœ€æ–°çš„äº¤æ˜“å“ç§ä¿¡æ¯ï¼ˆåŒ…å«ä¸Šå¸‚æ—¥æœŸï¼‰- å¼ºåˆ¶åˆ·æ–°
                instruments = await data_source_factory.get_instrument_list(exchange, force_refresh=True)

                if instruments:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    from database import db_ops
                    success = await db_ops.save_instrument_list(instruments)

                    if success:
                        dm_logger.info(f"[Main] Successfully refreshed {len(instruments)} instruments for {exchange}")
                    else:
                        dm_logger.error(f"[Main] Failed to save instruments for {exchange}")
                else:
                    dm_logger.warning(f"[Main] No instruments found for {exchange}")

        except Exception as e:
            dm_logger.error(f"[Main] Failed to refresh instrument list: {e}")
            raise

    async def update_daily_data(self, exchanges: Optional[list] = None, target_date=None):
        """æ›´æ–°æ—¥çº¿æ•°æ®"""
        try:
            dm_logger.info("[Main] Starting daily data update...")

            if exchanges is None:
                exchanges = ['SSE', 'SZSE', 'BSE']

            from datetime import date
            if target_date is None:
                target_date = date.today()

            # æ‰§è¡Œæ›´æ–°
            await data_manager.update_daily_data(exchanges, target_date)

            dm_logger.info("[Main] Daily data update completed")

        except Exception as e:
            dm_logger.error(f"[Main] Daily data update failed: {e}")
            raise

    async def download_single_instrument(self, instrument_id: str, start_date: date = None,
                                       end_date: date = None, resume: bool = False):
        """ä¸‹è½½æŒ‡å®šè‚¡ç¥¨çš„å†å²æ•°æ®"""
        try:
            dm_logger.info(f"[Main] Starting single instrument download: {instrument_id}")

            # éªŒè¯instrument_idæ ¼å¼
            if not self._validate_instrument_id(instrument_id):
                print(f"é”™è¯¯: æ— æ•ˆçš„è‚¡ç¥¨ä»£ç æ ¼å¼ '{instrument_id}'")
                print("æ­£ç¡®æ ¼å¼ç¤ºä¾‹: 000001.SZ, 600000.SSE")
                return

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            from datetime import date
            if start_date is None:
                start_date = date(1990, 1, 1)  # é»˜è®¤ä»1990å¹´å¼€å§‹
            if end_date is None:
                end_date = date.today()

            print(f"\nğŸ” å¼€å§‹ä¸‹è½½æŒ‡å®šè‚¡ç¥¨æ•°æ®:")
            print(f"   è‚¡ç¥¨ä»£ç : {instrument_id}")
            print(f"   æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            print(f"   ç»­ä¼ æ¨¡å¼: {'å¼€å¯' if resume else 'å…³é—­'}")

            # éªŒè¯è‚¡ç¥¨æ˜¯å¦å­˜åœ¨
            instrument_info = await self._get_instrument_info(instrument_id)
            if not instrument_info:
                print(f"é”™è¯¯: æ‰¾ä¸åˆ°è‚¡ç¥¨ä»£ç  '{instrument_id}'")
                print("æç¤º: è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å…ˆä¸‹è½½å¯¹åº”äº¤æ˜“æ‰€çš„è‚¡ç¥¨åˆ—è¡¨")
                return

            print(f"   è‚¡ç¥¨åç§°: {instrument_info.get('name', 'N/A')}")
            print(f"   äº¤æ˜“æ‰€: {instrument_info.get('exchange', 'N/A')}")
            print(f"   ä¸Šå¸‚æ—¥æœŸ: {instrument_info.get('listed_date', 'N/A')}")

            # æ‰§è¡Œä¸‹è½½
            success = await data_manager.download_single_instrument_data(
                instrument_id, instrument_info, start_date, end_date, resume
            )

            if success:
                print(f"\nâœ… è‚¡ç¥¨ {instrument_id} æ•°æ®ä¸‹è½½å®Œæˆ!")

                # æ˜¾ç¤ºä¸‹è½½ç»Ÿè®¡
                stats = await self._get_instrument_download_stats(instrument_id, start_date, end_date)
                if stats:
                    print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
                    print(f"   æ€»è®°å½•æ•°: {stats.get('total_quotes', 0):,}")
                    print(f"   æ•°æ®èŒƒå›´: {stats.get('first_date', 'N/A')} åˆ° {stats.get('last_date', 'N/A')}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå£
                    gaps = await data_manager.detect_data_gaps(
                        [instrument_info.get('exchange')], start_date, end_date
                    )
                    instrument_gaps = [gap for gap in gaps if gap.instrument_id == instrument_id]

                    if instrument_gaps:
                        print(f"   æ•°æ®ç¼ºå£: {len(instrument_gaps)} ä¸ª")
                        for gap in instrument_gaps[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                            print(f"      {gap.gap_start} åˆ° {gap.gap_end} ({gap.gap_days}å¤©)")
                        if len(instrument_gaps) > 3:
                            print(f"      ... è¿˜æœ‰ {len(instrument_gaps) - 3} ä¸ªç¼ºå£")
                    else:
                        print(f"   æ•°æ®å®Œæ•´æ€§: âœ… æ— ç¼ºå£")
            else:
                print(f"\nâŒ è‚¡ç¥¨ {instrument_id} æ•°æ®ä¸‹è½½å¤±è´¥!")
                print("è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")

            dm_logger.info(f"[Main] Single instrument download completed: {instrument_id}")

        except Exception as e:
            dm_logger.error(f"[Main] Single instrument download failed: {e}")
            print(f"ä¸‹è½½å¤±è´¥: {e}")
            raise
        finally:
            # ç¡®ä¿å…³é—­æ•°æ®æºï¼Œé¿å…èµ„æºæ³„æ¼
            try:
                from data_sources.source_factory import data_source_factory
                await data_source_factory.close_all()
                dm_logger.debug("[Main] DataSourceFactory closed successfully")
            except Exception as close_error:
                dm_logger.warning(f"[Main] Failed to close DataSourceFactory: {close_error}")

    def _validate_instrument_id(self, instrument_id: str) -> bool:
        """éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼"""
        return is_valid_standard_format(instrument_id)

    async def _get_instrument_info(self, instrument_id: str) -> dict:
        """è·å–è‚¡ç¥¨ä¿¡æ¯"""
        try:
            # è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼è¿›è¡ŒæŸ¥è¯¢
            db_instrument_id = convert_to_database_format(instrument_id)
            dm_logger.info(f"[Main] Converting instrument ID: {instrument_id} -> {db_instrument_id}")
            return await data_manager.db_ops.get_instrument_by_id(db_instrument_id)
        except Exception as e:
            dm_logger.error(f"[Main] Failed to get instrument info: {e}")
            return None

    async def _get_instrument_download_stats(self, instrument_id: str, start_date: date, end_date: date) -> dict:
        """è·å–è‚¡ç¥¨ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
            db_instrument_id = convert_to_database_format(instrument_id)

            # è·å–æ•°æ®è®°å½•æ•°
            quote_count = await data_manager.db_ops.count_quotes_by_instrument(
                db_instrument_id, start_date, end_date
            )

            # è·å–æ•°æ®æ—¥æœŸèŒƒå›´
            date_range = await data_manager.db_ops.get_instrument_date_range(
                db_instrument_id, start_date, end_date
            )

            return {
                'total_quotes': quote_count,
                'first_date': date_range.get('start_date'),
                'last_date': date_range.get('end_date')
            }
        except Exception as e:
            dm_logger.error(f"[Main] Failed to get download stats: {e}")
            return {}

    async def run_job(self, job_id: str):
        """è¿è¡ŒæŒ‡å®šä»»åŠ¡"""
        try:
            scheduler_logger.info(f"[Main] Running job: {job_id}")

            # ç›´æ¥æ‰§è¡Œä»»åŠ¡ï¼Œé¿å…è°ƒåº¦å™¨å¤æ‚æ€§
            from scheduler.tasks import scheduled_tasks

            if job_id == 'trading_calendar_update':
                # ä»é…ç½®è·å–å‚æ•°
                job_config = self.config.get_nested(f'scheduler_config.jobs.{job_id}', {})
                if not job_config:
                    scheduler_logger.error(f"[Main] Job {job_id} configuration not found")
                    return False

                params = job_config.get('parameters', {})
                success = await scheduled_tasks.trading_calendar_update(
                    exchanges=params.get('exchanges'),
                    update_future_months=params.get('update_future_months', 6),
                    force_update=params.get('force_update', False),
                    validate_holidays=params.get('validate_holidays', True)
                )

                if success:
                    scheduler_logger.info(f"[Main] Job {job_id} completed successfully")
                else:
                    scheduler_logger.error(f"[Main] Job {job_id} failed")
                return success

            elif job_id == 'daily_data_update':
                # ä»é…ç½®è·å–å‚æ•°
                job_config = self.config.get_nested(f'scheduler_config.jobs.{job_id}', {})
                if not job_config:
                    scheduler_logger.error(f"[Main] Job {job_id} configuration not found")
                    return False

                params = job_config.get('parameters', {})
                success = await scheduled_tasks.daily_data_update(
                    exchanges=params.get('exchanges'),
                    wait_for_market_close=params.get('wait_for_market_close', True),
                    market_close_delay_minutes=params.get('market_close_delay_minutes', 15),
                    enable_trading_day_check=params.get('enable_trading_day_check', True)
                )

                if success:
                    scheduler_logger.info(f"[Main] Job {job_id} completed successfully")
                else:
                    scheduler_logger.error(f"[Main] Job {job_id} failed")
                return success

            else:
                # å›é€€åˆ°è°ƒåº¦å™¨æ–¹å¼
                scheduler_logger.warning(f"[Main] Job {job_id} not implemented directly, falling back to scheduler")
                success = await task_scheduler.run_job_now(job_id)
                if success:
                    scheduler_logger.info(f"[Main] Job {job_id} scheduled successfully")
                else:
                    scheduler_logger.error(f"[Main] Failed to schedule job {job_id}")
                return success

        except Exception as e:
            scheduler_logger.error(f"[Main] Failed to run job {job_id}: {e}")
            import traceback
            scheduler_logger.error(f"[Main] Exception details: {traceback.format_exc()}")
            return False

    async def show_system_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        try:
            status = await data_manager.get_system_status()

            print("\n" + "="*60)
            print("         QUOTE SYSTEM STATUS")
            print("="*60)

            # æ•°æ®ç®¡ç†å™¨çŠ¶æ€
            dm_status = status.get('data_manager', {})
            print(f"\nğŸ“Š Data Manager:")
            print(f"   Running: {dm_status.get('is_running', False)}")
            if dm_status.get('download_progress'):
                progress = dm_status['download_progress']
                print(f"   Download Progress: {progress.get('success_rate', 0):.1f}%")
                print(f"   Processed: {progress.get('processed_instruments', 0)}/{progress.get('total_instruments', 0)}")

            # æ•°æ®åº“çŠ¶æ€
            db_status = status.get('database', {})
            print(f"\nğŸ’¾ Database:")
            print(f"   Instruments: {db_status.get('instruments_count', 0):,}")
            print(f"   Quotes: {db_status.get('quotes_count', 0):,}")
            if db_status.get('quotes_date_range'):
                date_range = db_status['quotes_date_range']
                print(f"   Date Range: {date_range.get('start_date', 'N/A')} to {date_range.get('end_date', 'N/A')}")

            # ç¼“å­˜çŠ¶æ€
            cache_status = status.get('cache', {})
            print(f"\nâš¡ Cache:")
            print(f"   Enabled: {cache_status.get('cache_enabled', False)}")
            if cache_status.get('quote_cache'):
                qc = cache_status['quote_cache']
                print(f"   Quote Cache: {qc.get('active_entries', 0)} active entries")

            # æ•°æ®æºçŠ¶æ€
            sources_status = status.get('data_sources', {})
            print(f"\nğŸ”— Data Sources:")
            for source, is_healthy in sources_status.items():
                status_icon = "âœ…" if is_healthy else "âŒ"
                print(f"   {status_icon} {source}: {'Healthy' if is_healthy else 'Unhealthy'}")

            # è°ƒåº¦å™¨çŠ¶æ€
            scheduler_status = task_scheduler.get_all_jobs_status()
            print(f"\nâ° Scheduler:")
            print(f"   Running: {scheduler_status.get('scheduler_running', False)}")
            print(f"   Total Jobs: {scheduler_status.get('total_jobs', 0)}")

            print("\n" + "="*60)

        except Exception as e:
            scheduler_logger.error(f"[Main] Failed to get system status: {e}")
            print(f"Error getting system status: {e}")

    async def _initialize_telegram_bot(self):
        """æå‰åˆå§‹åŒ–TelegramBot"""
        try:
            tgbot_logger.info("[Main] Initialization of TelegramBot...")

            # æ£€æŸ¥Telegramé…ç½®
            telegram_config = self.config.get_nested('telegram_config', {})
            if not telegram_config.get('enabled', False):
                tgbot_logger.info("[Main] Telegram disabled, skipping early bot initialization")
                return

            # åˆ›å»ºå¹¶åˆå§‹åŒ–TelegramBot
            from utils.tgbot import TelegramBot
            telegram_bot = TelegramBot()
            await telegram_bot.create_bot_instance()

            # ä¿å­˜å¼•ç”¨ä»¥ä¾¿æ¸…ç†
            self._telegram_bot = telegram_bot
            tgbot_logger.info("[Main] TelegramBot initialized successfully")

        except Exception as e:
            tgbot_logger.error(f"[Main] Failed to initialize TelegramBot early: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ

    async def _initialize_task_manager(self):
        """åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†æœºå™¨äºº"""
        try:
            scheduler_logger.info("[Main] Initializing task manager bot...")

            # ä½¿ç”¨å·²åˆå§‹åŒ–çš„TelegramBot
            if not hasattr(self, '_telegram_bot') or not self._telegram_bot:
                scheduler_logger.warning("[Main] TelegramBot not initialized early, cannot create task manager")
                return

            telegram_bot = self._telegram_bot
            scheduler_logger.debug("[Main] Using pre-initialized TelegramBot for task manager")

            # åˆ›å»ºä»»åŠ¡ç®¡ç†æœºå™¨äººå®ä¾‹
            self.task_manager_bot = TaskManagerBot(
                telegram_bot=telegram_bot,
                task_scheduler=task_scheduler,
                job_config_manager=job_config_manager,
                scheduler_monitor=self.scheduler_monitor,
                config_manager=self.config,
                logger=scheduler_logger
            )

            # åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†æœºå™¨äºº
            await self.task_manager_bot.initialize()

            # ä¿å­˜TelegramBotå¼•ç”¨ä»¥ä¾¿æ¸…ç†
            self._telegram_bot = telegram_bot

            scheduler_logger.info("[Main] Task manager bot initialized successfully")

        except Exception as e:
            scheduler_logger.error(f"[Main] Failed to initialize task manager bot: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ
            self.task_manager_bot = None

    async def shutdown(self):
        """å…³é—­ç³»ç»Ÿ"""
        try:
            scheduler_logger.info("[Main] Shutting down Quote System...")

            # å…³é—­ä»»åŠ¡ç®¡ç†æœºå™¨äºº
            if self.task_manager_bot:
                await self.task_manager_bot.cleanup()
                self.task_manager_bot = None

            # å…³é—­TelegramBot
            if self._telegram_bot:
                await self._telegram_bot.disconnect()
                self._telegram_bot = None

            # å…³é—­è°ƒåº¦å™¨
            await task_scheduler.shutdown()

            # å…³é—­æ•°æ®æºå·¥å‚
            from data_sources.source_factory import data_source_factory
            await data_source_factory.close_all()

            # æ¸…ç†è¿›ç¨‹ç®¡ç†å™¨
            self.process_manager.cleanup(self.service_name)

            scheduler_logger.info("[Main] Quote System shutdown completed")

        except Exception as e:
            scheduler_logger.error(f"[Main] Error during shutdown: {e}")

    def _get_preset_exchanges(self, preset: str) -> list:
        """è·å–é¢„è®¾ç»„åˆå¯¹åº”çš„äº¤æ˜“æ‰€åˆ—è¡¨"""
        try:
            presets = self.config.get_nested('data_config.market_presets', {})
            if preset not in presets:
                dm_logger.error(f"[Main] Unknown preset '{preset}'. Available presets: {list(presets.keys())}")
                raise ValueError(f"Unknown preset: {preset}")

            exchanges = presets[preset]
            dm_logger.info(f"[Main] Preset '{preset}' corresponds to exchanges: {exchanges}")
            return exchanges

        except Exception as e:
            dm_logger.error(f"[Main] Failed to get preset exchanges: {e}")
            raise

    async def list_market_presets(self):
        """æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å¸‚åœºé¢„è®¾"""
        try:
            presets = self.config.get_nested('data_config.market_presets', {})

            print("\n" + "="*60)
            print("         å¯ç”¨å¸‚åœºé¢„è®¾ç»„åˆ")
            print("="*60)

            preset_descriptions = {
                "a_shares": "Aè‚¡å¸‚åœº (ä¸Šæµ·+æ·±åœ³+åŒ—äº¬)",
                "hk_stocks": "æ¸¯è‚¡å¸‚åœº",
                "us_stocks": "ç¾è‚¡å¸‚åœº (çº³æ–¯è¾¾å…‹+çº½äº¤æ‰€)",
                "mainland": "å¤§é™†è‚¡å¸‚ (ä¸Šæµ·+æ·±åœ³+åŒ—äº¬)",
                "overseas": "æµ·å¤–å¸‚åœº (æ¸¯è‚¡+ç¾è‚¡)",
                "chinese": "ä¸­èµ„è‚¡å¸‚åœº (Aè‚¡+æ¸¯è‚¡)",
                "global": "å…¨çƒä¸»è¦å¸‚åœº (ç¾è‚¡)",
                "all_markets": "å…¨éƒ¨å¸‚åœº"
            }

            for preset_name, exchanges in presets.items():
                description = preset_descriptions.get(preset_name, "è‡ªå®šä¹‰ç»„åˆ")
                exchange_str = ", ".join(exchanges)
                print(f"\nğŸ“Š {preset_name:12} - {description}")
                print(f"   äº¤æ˜“æ‰€: {exchange_str}")
                print(f"   å‘½ä»¤: python main.py download --preset {preset_name}")

            print("\n" + "="*60)
            print("ä½¿ç”¨ç¤ºä¾‹:")
            print("  python main.py download --preset a_shares")
            print("  python main.py download --preset us_stocks --years 2020 2021 2022")
            print("="*60)

        except Exception as e:
            dm_logger.error(f"[Main] Failed to list presets: {e}")
            print(f"Error listing presets: {e}")

    async def interactive_download(self, mode: str = 'both'):
        """äº¤äº’å¼ä¸‹è½½æ¨¡å¼"""
        try:
            print("\n" + "="*60)
            print("         äº¤äº’å¼å†å²æ•°æ®ä¸‹è½½")
            print("="*60)

            exchanges = None
            years = None

            # äº¤äº’é€‰æ‹©äº¤æ˜“æ‰€
            if mode in ['market', 'both']:
                print("\nğŸ“Š è¯·é€‰æ‹©è¦ä¸‹è½½çš„å¸‚åœº:")
                print("1. Aè‚¡å¸‚åœº (SSE+SZSE)")
                print("2. æ¸¯è‚¡å¸‚åœº (HKEX)")
                print("3. ç¾è‚¡å¸‚åœº (NASDAQ+NYSE)")
                print("4. å¤§é™†è‚¡å¸‚ (SSE+SZSE)")
                print("5. æµ·å¤–å¸‚åœº (HKEX+NASDAQ+NYSE)")
                print("6. ä¸­èµ„è‚¡å¸‚åœº (SSE+SZSE+HKEX)")
                print("7. å…¨çƒä¸»è¦å¸‚åœº (NASDAQ+NYSE)")
                print("8. å…¨éƒ¨å¸‚åœº")
                print("9. è‡ªå®šä¹‰äº¤æ˜“æ‰€")
                print("0. æŸ¥çœ‹æ‰€æœ‰é¢„è®¾")

                while True:
                    try:
                        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-9): ").strip()
                        if choice == '0':
                            await self.list_market_presets()
                            continue
                        elif choice == '1':
                            exchanges = ['SSE', 'SZSE']
                            break
                        elif choice == '2':
                            exchanges = ['HKEX']
                            break
                        elif choice == '3':
                            exchanges = ['NASDAQ', 'NYSE']
                            break
                        elif choice == '4':
                            exchanges = ['SSE', 'SZSE']
                            break
                        elif choice == '5':
                            exchanges = ['HKEX', 'NASDAQ', 'NYSE']
                            break
                        elif choice == '6':
                            exchanges = ['SSE', 'SZSE', 'HKEX']
                            break
                        elif choice == '7':
                            exchanges = ['NASDAQ', 'NYSE']
                            break
                        elif choice == '8':
                            exchanges = ['SSE', 'SZSE', 'HKEX', 'NASDAQ', 'NYSE']
                            break
                        elif choice == '9':
                            print("\nå¯ç”¨äº¤æ˜“æ‰€: SSE, SZSE, HKEX, NASDAQ, NYSE")
                            exchanges_input = input("è¯·è¾“å…¥äº¤æ˜“æ‰€ä»£ç  (ç”¨ç©ºæ ¼åˆ†éš”): ").strip().upper()
                            exchanges = exchanges_input.split()
                            valid_exchanges = {'SSE', 'SZSE', 'HKEX', 'NASDAQ', 'NYSE'}
                            exchanges = [ex for ex in exchanges if ex in valid_exchanges]
                            if not exchanges:
                                print("âŒ æ— æ•ˆçš„äº¤æ˜“æ‰€ä»£ç ")
                                continue
                            break
                        else:
                            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    except KeyboardInterrupt:
                        print("\n\næ“ä½œå·²å–æ¶ˆ")
                        return

                print(f"âœ… å·²é€‰æ‹©: {', '.join(exchanges)}")

            # äº¤äº’é€‰æ‹©å¹´ä»½
            if mode in ['year', 'both']:
                print("\nğŸ“… è¯·é€‰æ‹©å¹´ä»½èŒƒå›´:")
                print("1. æœ€è¿‘3å¹´ (2022-2025)")
                print("2. æœ€è¿‘5å¹´ (2020-2025)")
                print("3. æœ€è¿‘10å¹´ (2015-2025)")
                print("4. å…¨éƒ¨å†å² (1990-2025)")
                print("5. è‡ªå®šä¹‰å¹´ä»½")

                while True:
                    try:
                        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()
                        current_year = 2025

                        if choice == '1':
                            years = list(range(current_year - 3, current_year + 1))
                            break
                        elif choice == '2':
                            years = list(range(current_year - 5, current_year + 1))
                            break
                        elif choice == '3':
                            years = list(range(current_year - 10, current_year + 1))
                            break
                        elif choice == '4':
                            years = list(range(1990, current_year + 1))
                            break
                        elif choice == '5':
                            years_input = input("è¯·è¾“å…¥å¹´ä»½åˆ—è¡¨ (ç”¨ç©ºæ ¼åˆ†éš”ï¼Œå¦‚: 2020 2021 2022): ").strip()
                            try:
                                years = [int(year.strip()) for year in years_input.split()]
                                if not years:
                                    print("âŒ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªå¹´ä»½")
                                    continue
                                years = sorted(years)
                                break
                            except ValueError:
                                print("âŒ å¹´ä»½æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
                                continue
                        else:
                            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    except KeyboardInterrupt:
                        print("\n\næ“ä½œå·²å–æ¶ˆ")
                        return

                print(f"âœ… å·²é€‰æ‹©å¹´ä»½: {min(years)}-{max(years)} ({len(years)}å¹´)")

            # ç¡®è®¤ä¸‹è½½
            print(f"\nğŸ“‹ ä¸‹è½½é…ç½®:")
            print(f"   äº¤æ˜“æ‰€: {', '.join(exchanges) if exchanges else 'å…¨éƒ¨'}")
            print(f"   å¹´ä»½èŒƒå›´: {min(years)}-{max(years)} ({len(years)}å¹´)" if years else "   å¹´ä»½: ä½¿ç”¨é…ç½®é»˜è®¤")

            confirm = input("\næ˜¯å¦å¼€å§‹ä¸‹è½½? (y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("ä¸‹è½½å·²å–æ¶ˆ")
                return

            # å¼€å§‹ä¸‹è½½
            print("\nğŸš€ å¼€å§‹ä¸‹è½½å†å²æ•°æ®...")
            await self.download_historical_data(exchanges, years)

        except KeyboardInterrupt:
            print("\n\näº¤äº’å¼ä¸‹è½½å·²å–æ¶ˆ")
        except Exception as e:
            dm_logger.error(f"[Main] Interactive download failed: {e}")
            print(f"äº¤äº’å¼ä¸‹è½½å¤±è´¥: {e}")

    async def detect_data_gaps(self, exchanges: Optional[list] = None, start_date: str = None,
                              end_date: str = None, severity_filter: str = None,
                              output_file: str = None, detailed: bool = False):
        """æ£€æµ‹æ•°æ®ç¼ºå£"""
        try:
            from datetime import datetime

            dm_logger.info("[Main] Starting data gap detection...")

            # å¤„ç†æ—¥æœŸå‚æ•°
            start_date_obj = None
            end_date_obj = None

            if start_date:
                try:
                    start_date_obj = datetime.strptime(start_date, '%Y-%m-%d').date()
                except ValueError:
                    print(f"é”™è¯¯: å¼€å§‹æ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                    return

            if end_date:
                try:
                    end_date_obj = datetime.strptime(end_date, '%Y-%m-%d').date()
                except ValueError:
                    print(f"é”™è¯¯: ç»“æŸæ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                    return

            # æ£€æŸ¥æ—¥æœŸèŒƒå›´
            if start_date_obj and end_date_obj and start_date_obj > end_date_obj:
                print(f"é”™è¯¯: å¼€å§‹æ—¥æœŸ {start_date_obj} ä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ {end_date_obj}")
                return

            # è®¾ç½®é»˜è®¤äº¤æ˜“æ‰€
            if exchanges is None:
                exchanges = ['SSE', 'SZSE', 'BSE']

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if start_date_obj is None:
                start_date_obj = date(1990, 1, 1)  # ä»1990å¹´å¼€å§‹
            if end_date_obj is None:
                end_date_obj = date.today()

            print(f"\nğŸ” å¼€å§‹æ£€æµ‹æ•°æ®ç¼ºå£...")
            print(f"   äº¤æ˜“æ‰€: {', '.join(exchanges)}")
            print(f"   æ—¥æœŸèŒƒå›´: {start_date_obj} åˆ° {end_date_obj}")

            # æ‰§è¡ŒGAPæ£€æµ‹
            gaps = await data_manager.detect_data_gaps(exchanges, start_date_obj, end_date_obj)

            # æŒ‰ä¸¥é‡ç¨‹åº¦è¿‡æ»¤
            if severity_filter:
                original_count = len(gaps)
                gaps = [gap for gap in gaps if gap.severity == severity_filter]
                print(f"   ä¸¥é‡ç¨‹åº¦è¿‡æ»¤: {severity_filter} ({original_count} -> {len(gaps)})")

            # ç”ŸæˆæŠ¥å‘Š
            report = await self._generate_gap_report(gaps, detailed, exchanges, start_date_obj, end_date_obj)

            # è¾“å‡ºç»“æœ
            self._display_gap_report(report, detailed)

            # ä¿å­˜åˆ°æ–‡ä»¶
            if output_file:
                await self._save_gap_report(report, output_file)
                print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

            dm_logger.info(f"[Main] Gap detection completed. Found {len(gaps)} gaps.")

        except Exception as e:
            dm_logger.error(f"[Main] Gap detection failed: {e}")
            print(f"ç¼ºå£æ£€æµ‹å¤±è´¥: {e}")

    async def _generate_gap_report(self, gaps, detailed: bool, exchanges: list,
                                 start_date: date, end_date: date) -> dict:
        """ç”ŸæˆGAPæ£€æµ‹æŠ¥å‘Š"""
        from collections import defaultdict, Counter

        # åŸºæœ¬ç»Ÿè®¡
        total_gaps = len(gaps)
        severity_counts = Counter(gap.severity for gap in gaps)
        exchange_counts = Counter(gap.exchange for gap in gaps)

        # æŒ‰è‚¡ç¥¨åˆ†ç»„
        gaps_by_stock = defaultdict(list)
        for gap in gaps:
            key = f"{gap.symbol}.{gap.exchange}"
            gaps_by_stock[key].append(gap)

        # è¯¦ç»†ä¿¡æ¯
        stock_details = {}
        if detailed:
            for stock_key, stock_gaps in gaps_by_stock.items():
                stock_details[stock_key] = {
                    'total_gaps': len(stock_gaps),
                    'total_missing_days': sum(gap.gap_days for gap in stock_gaps),
                    'gaps': [
                        {
                            'start_date': gap.gap_start.isoformat(),
                            'end_date': gap.gap_end.isoformat(),
                            'days': gap.gap_days,
                            'severity': gap.severity,
                            'recommendation': gap.recommendation,
                            'missing_dates': [d.isoformat() for d in gap.missing_dates]
                        }
                        for gap in sorted(stock_gaps, key=lambda x: x.gap_start)
                    ]
                }

        return {
            'detection_info': {
                'exchanges': exchanges,
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'detection_time': datetime.now().isoformat()
            },
            'summary': {
                'total_gaps': total_gaps,
                'affected_stocks': len(gaps_by_stock),
                'severity_distribution': dict(severity_counts),
                'exchange_distribution': dict(exchange_counts)
            },
            'stock_details': stock_details if detailed else None,
            'top_affected_stocks': data_manager.get_top_affected_stocks(gaps, 10)
        }

    def _display_gap_report(self, report: dict, detailed: bool):
        """æ˜¾ç¤ºGAPæ£€æµ‹æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("                     æ•°æ®ç¼ºå£æ£€æµ‹æŠ¥å‘Š")
        print("="*80)

        # æ£€æµ‹ä¿¡æ¯
        info = report['detection_info']
        print(f"\nğŸ“‹ æ£€æµ‹ä¿¡æ¯:")
        print(f"   äº¤æ˜“æ‰€: {', '.join(info['exchanges'])}")
        print(f"   æ£€æµ‹èŒƒå›´: {info['start_date']} åˆ° {info['end_date']}")
        print(f"   æ£€æµ‹æ—¶é—´: {info['detection_time'][:19]}")

        # æ‘˜è¦ç»Ÿè®¡
        summary = report['summary']
        print(f"\nğŸ“Š ç¼ºå£æ‘˜è¦:")
        print(f"   æ€»ç¼ºå£æ•°: {summary['total_gaps']:,}")
        print(f"   å—å½±å“è‚¡ç¥¨æ•°: {summary['affected_stocks']:,}")

        print(f"\nğŸ¯ ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:")
        for severity, count in summary['severity_distribution'].items():
            percentage = (count / summary['total_gaps'] * 100) if summary['total_gaps'] > 0 else 0
            print(f"   {severity:8}: {count:6,} ({percentage:5.1f}%)")

        print(f"\nğŸ“ˆ äº¤æ˜“æ‰€åˆ†å¸ƒ:")
        for exchange, count in summary['exchange_distribution'].items():
            percentage = (count / summary['total_gaps'] * 100) if summary['total_gaps'] > 0 else 0
            print(f"   {exchange:6}: {count:6,} ({percentage:5.1f}%)")

        # æœ€å—å½±å“çš„è‚¡ç¥¨
        if report['top_affected_stocks']:
            print(f"\nğŸ” å—å½±å“æœ€ä¸¥é‡çš„è‚¡ç¥¨ (å‰{len(report['top_affected_stocks'])}å):")
            print(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<12} {'ä¸¥é‡åˆ†æ•°':<10} {'ç¼ºå¤±å¤©æ•°':<8}")
            print("-" * 45) # è°ƒæ•´åˆ†éš”çº¿é•¿åº¦ä»¥åŒ¹é…æ–°çš„åˆ—å®½
            for i, stock in enumerate(report['top_affected_stocks'], 1):
                print(f"{i:<4} {stock['symbol']:<12} {stock['severity_score']:<10.2f} {stock['total_missing_days']:<8}") # æ ¼å¼åŒ–åˆ†æ•°å’Œå¤©æ•°

        # è¯¦ç»†ä¿¡æ¯
        if detailed and report['stock_details']:
            print(f"\nğŸ“‹ è¯¦ç»†è‚¡ç¥¨ç¼ºå£ä¿¡æ¯:")
            for stock_key, details in sorted(report['stock_details'].items()):
                if details['total_gaps'] > 0:
                    print(f"\n   ğŸ“ˆ {stock_key} (ç¼ºå£æ•°: {details['total_gaps']}, ç¼ºå¤±å¤©æ•°: {details['total_missing_days']})")

                    # æ˜¾ç¤ºç¼ºå¤±çš„æ—¥æœŸ
                    all_missing_dates = []
                    for gap in details['gaps']:
                        all_missing_dates.extend(gap['missing_dates'])

                    if all_missing_dates:
                        # æŒ‰æ—¥æœŸæ’åº
                        all_missing_dates.sort()

                        # å†³å®šæ˜¾ç¤ºå“ªäº›æ—¥æœŸ
                        if len(all_missing_dates) <= 10:
                            # å¦‚æœç¼ºå¤±å¤©æ•°åœ¨10å¤©ä»¥å†…ï¼Œæ˜¾ç¤ºå…¨éƒ¨
                            dates_to_show = all_missing_dates
                            show_more = False
                        else:
                            # å¦‚æœè¶…è¿‡10å¤©ï¼Œåªæ˜¾ç¤ºå‰10å¤©
                            dates_to_show = all_missing_dates[:10]
                            show_more = True

                        # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
                        date_strs = [d.replace('-', '/') for d in dates_to_show]

                        # æ¯è¡Œæ˜¾ç¤º5ä¸ªæ—¥æœŸ
                        for i in range(0, len(date_strs), 5):
                            line_dates = date_strs[i:i+5]
                            print(f"      ç¼ºå¤±æ—¥æœŸ: {', '.join(line_dates)}")

                        if show_more:
                            print(f"      ... è¿˜æœ‰ {len(all_missing_dates) - 10} ä¸ªç¼ºå¤±æ—¥æœŸ")

                    # æ˜¾ç¤ºç¼ºå£èŒƒå›´ä¿¡æ¯
                    for gap in details['gaps'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªç¼ºå£èŒƒå›´
                        print(f"      ç¼ºå£èŒƒå›´: {gap['start_date']} åˆ° {gap['end_date']} "
                              f"({gap['days']}å¤©, {gap['severity']})")
                    if details['total_gaps'] > 3:
                        print(f"      ... è¿˜æœ‰ {details['total_gaps'] - 3} ä¸ªç¼ºå£èŒƒå›´")

        print("\n" + "="*80)

    async def _save_gap_report(self, report: dict, output_file: str):
        """ä¿å­˜GAPæŠ¥å‘Šåˆ°æ–‡ä»¶"""
        import json
        import os

        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_file), exist_ok=True)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

        except Exception as e:
            dm_logger.error(f"[Main] Failed to save gap report: {e}")
            raise

    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        try:
            import signal

            def signal_handler(signum, frame):
                scheduler_logger.info(f"[Main] Received signal {signum}, shutting down...")
                self.running = False

            signal.signal(signal.SIGINT, signal_handler)
            signal.signal(signal.SIGTERM, signal_handler)

        except Exception as e:
            scheduler_logger.warning(f"[Main] Failed to setup signal handlers: {e}")


def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Quote System - è‚¡ç¥¨è¡Œæƒ…æ•°æ®ç®¡ç†ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py scheduler                    # å¯åŠ¨è°ƒåº¦å™¨æ¨¡å¼
  python main.py api --host 0.0.0.0 --port 8000  # å¯åŠ¨APIæœåŠ¡å™¨
  python main.py full --host 0.0.0.0 --port 8000  # å¯åŠ¨å®Œæ•´ç³»ç»Ÿï¼ˆè°ƒåº¦å™¨ + APIæœåŠ¡ï¼‰
  python main.py download --exchanges SSE SZSE --years 2023 2024  # ä¸‹è½½å†å²æ•°æ®
  python main.py download --exchanges SZSE --start-date 2024-01-01 --end-date 2024-12-31  # ä¸‹è½½æŒ‡å®šæ—¥æœŸèŒƒå›´
  python main.py download --instrument-id 000001.SZ --start-date 2024-01-01 --end-date 2024-12-31  # ä¸‹è½½æŒ‡å®šè‚¡ç¥¨
  python main.py update --exchanges SSE          # æ›´æ–°æ—¥çº¿æ•°æ®
  python main.py status                         # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
  python main.py job --job-id daily_data_update  # è¿è¡ŒæŒ‡å®šä»»åŠ¡
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # è°ƒåº¦å™¨æ¨¡å¼
    scheduler_parser = subparsers.add_parser('scheduler', help='å¯åŠ¨è°ƒåº¦å™¨æ¨¡å¼')

    # APIæœåŠ¡å™¨
    api_parser = subparsers.add_parser('api', help='å¯åŠ¨APIæœåŠ¡å™¨')
    api_parser.add_argument('--host', default='0.0.0.0', help='ç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0)')
    api_parser.add_argument('--port', type=int, default=8000, help='ç›‘å¬ç«¯å£ (é»˜è®¤: 8000)')

    # å®Œæ•´ç³»ç»Ÿï¼ˆè°ƒåº¦å™¨ + APIï¼‰
    full_parser = subparsers.add_parser('full', help='å¯åŠ¨å®Œæ•´ç³»ç»Ÿï¼ˆè°ƒåº¦å™¨ + APIæœåŠ¡ï¼‰')
    full_parser.add_argument('--host', default='0.0.0.0', help='APIç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0)')
    full_parser.add_argument('--port', type=int, default=8000, help='APIç›‘å¬ç«¯å£ (é»˜è®¤: 8000)')

    # ä¸‹è½½å†å²æ•°æ®
    download_parser = subparsers.add_parser('download', help='ä¸‹è½½å†å²æ•°æ®')
    download_parser.add_argument('--exchanges', nargs='+', choices=['SSE', 'SZSE', 'HKEX', 'NASDAQ', 'NYSE'],
                               help='äº¤æ˜“æ‰€åˆ—è¡¨')
    download_parser.add_argument('--years', type=int, nargs='+', help='å¹´ä»½åˆ—è¡¨')
    download_parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    download_parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    download_parser.add_argument('--preset', choices=['a_shares', 'hk_stocks', 'us_stocks', 'mainland', 'overseas', 'chinese', 'global'],
                               help='å¸‚åœºé¢„è®¾ç»„åˆ')
    download_parser.add_argument('--instrument-id', type=str, help='æŒ‡å®šè‚¡ç¥¨ä»£ç ä¸‹è½½ (å¦‚: 000001.SZ)')
    download_parser.add_argument('--list-presets', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å¸‚åœºé¢„è®¾')
    download_parser.add_argument('--resume', action='store_true', help='ç»­ä¼ æ¨¡å¼ï¼ˆé»˜è®¤å¼€å¯ï¼Œä½¿ç”¨--no-resumeç¦ç”¨ï¼‰')
    download_parser.add_argument('--no-resume', action='store_true', help='é‡ç½®è¿›åº¦é‡æ–°ä¸‹è½½')
    download_parser.set_defaults(resume=True)

    # æ›´æ–°æ—¥çº¿æ•°æ®
    update_parser = subparsers.add_parser('update', help='æ›´æ–°æ—¥çº¿æ•°æ®')
    update_parser.add_argument('--exchanges', nargs='+', choices=['SSE', 'SZSE', 'HKEX', 'NASDAQ', 'NYSE'],
                             help='äº¤æ˜“æ‰€åˆ—è¡¨ (é»˜è®¤: å…¨éƒ¨)')

    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status_parser = subparsers.add_parser('status', help='æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€')

    # è¿è¡Œä»»åŠ¡
    job_parser = subparsers.add_parser('job', help='è¿è¡ŒæŒ‡å®šä»»åŠ¡')
    job_parser.add_argument('--job-id', required=True, help='ä»»åŠ¡ID')

    # äº¤äº’å¼ä¸‹è½½
    interactive_parser = subparsers.add_parser('interactive', help='äº¤äº’å¼ä¸‹è½½æ¨¡å¼')
    interactive_parser.add_argument('--mode', choices=['market', 'year', 'both'], default='both',
                                  help='äº¤äº’é€‰æ‹©æ¨¡å¼')

    # GAPæ£€æµ‹
    gap_parser = subparsers.add_parser('gap', help='æ•°æ®ç¼ºå£æ£€æµ‹')
    gap_parser.add_argument('--exchanges', nargs='+', choices=['SSE', 'SZSE', 'HKEX', 'NASDAQ', 'NYSE'],
                           help='äº¤æ˜“æ‰€åˆ—è¡¨ (é»˜è®¤: å…¨éƒ¨)')
    gap_parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    gap_parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    gap_parser.add_argument('--severity', choices=['low', 'medium', 'high', 'critical'],
                           help='ä¸¥é‡ç¨‹åº¦è¿‡æ»¤')
    gap_parser.add_argument('--output', type=str, help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    gap_parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„è‚¡ç¥¨çº§åˆ«ç¼ºå£ä¿¡æ¯')

    return parser


async def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    try:
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        system = QuoteSystem()

        # å¯¹äºéœ€è¦å•å®ä¾‹æ£€æŸ¥çš„å‘½ä»¤ï¼Œå…ˆæ£€æŸ¥è¿›ç¨‹çŠ¶æ€
        if args.command in ['full', 'scheduler', 'api']:
            # åœ¨åˆå§‹åŒ–å‰æ£€æŸ¥å•å®ä¾‹
            if not system.process_manager.check_single_instance("QuoteSystem"):
                scheduler_logger.error(f"[Main] Another instance is already running. Exiting...")
                return

        # æ ¹æ®å‘½ä»¤ç±»å‹é€‰æ‹©åˆå§‹åŒ–æ–¹å¼
        if args.command in ['gap', 'api', 'download', 'update', 'status', 'interactive', 'job']:
            # è½»é‡çº§åˆå§‹åŒ–ï¼Œä¸éœ€è¦è°ƒåº¦å™¨
            await system.initialize_lightweight()
        else:
            # å®Œæ•´åˆå§‹åŒ–ï¼ŒåŒ…æ‹¬è°ƒåº¦å™¨ï¼ˆscheduler, fullå‘½ä»¤éœ€è¦ï¼‰
            await system.initialize()

        # æ‰§è¡Œå¯¹åº”å‘½ä»¤
        if args.command == 'scheduler':
            await system.start_scheduler_only()

        elif args.command == 'api':
            await system.start_api_server(
                host=args.host if args.host != "0.0.0.0" else None,
                port=args.port if args.port != 8000 else None
            )

        elif args.command == 'full':
            await system.start_full_system(
                host=args.host if args.host != "0.0.0.0" else None,
                port=args.port if args.port != 8000 else None
            )

        elif args.command == 'download':
            # å¤„ç†é¢„è®¾å‚æ•°
            if args.list_presets:
                await system.list_market_presets()
            else:
                # å¤„ç†æ—¥æœŸå‚æ•°
                from datetime import datetime
                start_date = None
                end_date = None

                if args.start_date:
                    try:
                        start_date = datetime.strptime(args.start_date, '%Y-%m-%d').date()
                    except ValueError:
                        print(f"é”™è¯¯: å¼€å§‹æ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                        sys.exit(1)

                if args.end_date:
                    try:
                        end_date = datetime.strptime(args.end_date, '%Y-%m-%d').date()
                    except ValueError:
                        print(f"é”™è¯¯: ç»“æŸæ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                        sys.exit(1)

                # æ£€æŸ¥æ—¥æœŸèŒƒå›´æ˜¯å¦åˆç†
                if start_date and end_date and start_date > end_date:
                    print(f"é”™è¯¯: å¼€å§‹æ—¥æœŸ {start_date} ä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ {end_date}")
                    sys.exit(1)

                # å¤„ç†ç»­ä¼ å‚æ•°
                resume = args.resume and not args.no_resume

                # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†instrument_id
                if args.instrument_id:
                    # ä¸‹è½½æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
                    if not args.start_date or not args.end_date:
                        print("é”™è¯¯: ä½¿ç”¨ --instrument-id æ—¶å¿…é¡»æŒ‡å®š --start-date å’Œ --end-date")
                        sys.exit(1)
                    await system.download_single_instrument(args.instrument_id, start_date, end_date, resume)
                else:
                    # ä¸‹è½½å†å²æ•°æ®ï¼ˆåŸæœ‰çš„é€»è¾‘ï¼‰
                    await system.download_historical_data(args.exchanges, args.years, start_date, end_date, args.preset,
                                                        resume=resume)

        elif args.command == 'update':
            await system.update_daily_data(args.exchanges)

        elif args.command == 'status':
            await system.show_system_status()

        elif args.command == 'job':
            await system.run_job(args.job_id)

        elif args.command == 'interactive':
            await system.interactive_download(args.mode)

        elif args.command == 'gap':
            await system.detect_data_gaps(args.exchanges, args.start_date, args.end_date,
                                        args.severity, args.output, args.detailed)

        else:
            parser.print_help()

    except KeyboardInterrupt:
        scheduler_logger.info("[Main] Received keyboard interrupt")
    except Exception as e:
        scheduler_logger.error(f"[Main] System error: {e}")
        sys.exit(1)
    finally:
        # ç¡®ä¿åœ¨ç¨‹åºé€€å‡ºæ—¶å…³é—­æ‰€æœ‰æ•°æ®æºå’Œè¿æ¥
        try:
            # å…³é—­æ•°æ®æºè¿æ¥
            from data_sources.source_factory import data_source_factory
            if data_source_factory:
                await data_source_factory.close_all()
                scheduler_logger.debug("[Main] All data sources closed on exit")
        except Exception as e:
            scheduler_logger.warning(f"[Main] Failed to close data sources on exit: {e}")

        try:
            # å…³é—­Telegramè¿æ¥
            from utils.tgbot import TelegramBot
            # æ¸…ç†singletonå®ä¾‹
            if hasattr(TelegramBot, '_instance') and TelegramBot._instance:
                try:
                    # å°è¯•æ­£å¸¸å…³é—­è¿æ¥
                    if hasattr(TelegramBot._instance, 'bot_thon') and TelegramBot._instance.bot_thon:
                        await TelegramBot._instance.bot_thon.disconnect()
                        scheduler_logger.debug("[Main] Telegram connection closed on exit")
                except Exception as e:
                    scheduler_logger.warning(f"[Main] Failed to close Telegram connection: {e}")
                finally:
                    TelegramBot._instance = None
        except Exception as e:
            scheduler_logger.warning(f"[Main] Failed to cleanup Telegram bot: {e}")


if __name__ == "__main__":
    asyncio.run(main())